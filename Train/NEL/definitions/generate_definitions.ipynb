{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef625221",
   "metadata": {},
   "source": [
    "# URI Definitions Generator\n",
    "\n",
    "This notebook processes URIs from the GutBrainIE dataset to generate comprehensive definitions for Named Entity Linking (NEL). The workflow includes:\n",
    "\n",
    "1. **Data Loading & Validation**: Load URIs from CSV and validate their formats\n",
    "2. **Collection-based Definitions**: Extract definitions from existing annotation collections\n",
    "3. **External Definitions**: Retrieve definitions from external sources via URI resolution  \n",
    "4. **Definition Merging**: Combine definitions from both sources, removing duplicates\n",
    "5. **Output Generation**: Create multiple output formats for downstream processing\n",
    "\n",
    "The final outputs include:\n",
    "- `merged_uri_definitions.json`: Combined definitions for each URI\n",
    "- `split_uri_definitions.json`: Individual definitions with numeric IDs\n",
    "- `id_to_uri.json`: Mapping from definition IDs back to URIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0460e606",
   "metadata": {},
   "source": [
    "# IMPORTANT\n",
    "Before running, open the `find_uri_definitions.py` file and set the UMLS api key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2c907e",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Import required libraries and custom modules for URI definition processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Third-party imports  \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom module imports\n",
    "from find_uri_definitions import find_definition, find_definition_from_collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3431c7b",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and URI Validation\n",
    "\n",
    "Load the URIs from the CSV file and validate their formats. We expect URIs to contain specific domains (UMLS, PURL, W3ID, MeSH) to ensure they are valid biomedical ontology identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45267180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1155 has invalid URI: http://www.ebi.ac.uk/swo/SWO_0000243\n"
     ]
    }
   ],
   "source": [
    "# Load URIs from the CSV file\n",
    "uri_dataframe = pd.read_csv('../../Annotations/uris.csv', header=0)\n",
    "\n",
    "# Validate URI formats - check for expected biomedical ontology domains\n",
    "VALID_URI_DOMAINS = ['umls', 'purl', 'w3id', 'mesh']\n",
    "\n",
    "print(\"Validating URI formats...\")\n",
    "for row_index, row in uri_dataframe.iterrows():\n",
    "    # Skip header row (index 0)\n",
    "    if row_index == 0:\n",
    "        continue\n",
    "    \n",
    "    current_uri = row['uri']\n",
    "    \n",
    "    # Check if URI contains any of the valid domains\n",
    "    is_valid_uri = any(domain in current_uri for domain in VALID_URI_DOMAINS)\n",
    "    \n",
    "    if not is_valid_uri:\n",
    "        print(f'Warning: Row {row_index} has potentially invalid URI: {current_uri}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5d57a9",
   "metadata": {},
   "source": [
    "## Step 2: Extract Definitions from Collections\n",
    "\n",
    "Extract definitions for each URI from existing annotation collections (dev, train_platinum, train_gold). This provides context-specific definitions based on how entities are used in the dataset.\n",
    "\n",
    "**Progress saving**: Results are saved every 20 iterations to prevent data loss in case of interruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46940e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage for definitions extracted from collections\n",
    "uri_to_collection_definitions = {}\n",
    "\n",
    "# Define collection files to search for definitions\n",
    "annotation_collection_files = [\n",
    "    \"../../Annotations/Dev/json_format/dev.json\",\n",
    "    \"../../Annotations/Train/platinum_quality/json_format/train_platinum.json\",\n",
    "    \"../../Annotations/Train/gold_quality/json_format/train_gold.json\"\n",
    "]\n",
    "\n",
    "print(f\"Extracting definitions from {len(annotation_collection_files)} collection files...\")\n",
    "\n",
    "# Process each URI to find definitions in collections\n",
    "for row_index, row in tqdm(uri_dataframe.iterrows(), total=uri_dataframe.shape[0], desc=\"Processing URIs\"):\n",
    "    # Skip header row (index 0)\n",
    "    if row_index == 0:\n",
    "        continue\n",
    "    \n",
    "    current_uri = row['uri']\n",
    "    \n",
    "    try:\n",
    "        # Find definitions for this URI in the collection files\n",
    "        uri_to_collection_definitions[current_uri] = find_definition_from_collections(\n",
    "            current_uri, annotation_collection_files\n",
    "        )\n",
    "    except Exception as error:\n",
    "        print(f\"Error processing {current_uri}: {error}\")\n",
    "        uri_to_collection_definitions[current_uri] = []\n",
    "    \n",
    "    # Save progress every 20 iterations to prevent data loss\n",
    "    if row_index % 20 == 0:\n",
    "        with open('uri_collection_definitions.json', 'w', encoding='utf-8') as output_file:\n",
    "            json.dump(uri_to_collection_definitions, output_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Collection-based definitions extracted for {len(uri_to_collection_definitions)} URIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6cab81",
   "metadata": {},
   "source": [
    "## Step 3: Retrieve External Definitions\n",
    "\n",
    "Retrieve definitions by resolving URIs directly from external sources (ontology websites, APIs, etc.). \n",
    "\n",
    "**Resumable processing**: This cell can be run multiple times - it will load previously computed definitions and only process missing ones.\n",
    "\n",
    "**Special cases**: Some URIs require manual handling due to API limitations or specific formatting needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf3fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing definitions from 'uri_definitions.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1761/1761 [00:02<00:00, 860.22it/s] \n"
     ]
    }
   ],
   "source": [
    "# Load previously computed definitions if available (enables resumable processing)\n",
    "EXTERNAL_DEFINITIONS_FILE = 'uri_retrieved_definitions.json'\n",
    "\n",
    "if os.path.exists(EXTERNAL_DEFINITIONS_FILE):\n",
    "    print(f\"Loading existing definitions from '{EXTERNAL_DEFINITIONS_FILE}'\")\n",
    "    with open(EXTERNAL_DEFINITIONS_FILE, 'r', encoding='utf-8') as input_file:\n",
    "        previously_computed_definitions = json.load(input_file)\n",
    "else:\n",
    "    print(\"No existing definitions file found, starting from scratch\")\n",
    "    previously_computed_definitions = {}\n",
    "\n",
    "# Initialize storage for external definitions    \n",
    "uri_to_external_definitions = {}\n",
    "\n",
    "print(\"Retrieving definitions from external sources...\")\n",
    "\n",
    "# Process each URI to get external definitions\n",
    "for row_index, row in tqdm(uri_dataframe.iterrows(), total=uri_dataframe.shape[0], desc=\"Retrieving external definitions\"):\n",
    "    # Skip header row (index 0)\n",
    "    if row_index == 0:\n",
    "        continue\n",
    "    \n",
    "    current_uri = row['uri']\n",
    "    \n",
    "    # Skip if we already have definitions for this URI from previous runs\n",
    "    if current_uri in previously_computed_definitions and len(previously_computed_definitions[current_uri]) > 0:\n",
    "        uri_to_external_definitions[current_uri] = previously_computed_definitions[current_uri]\n",
    "        continue\n",
    "    \n",
    "    # Handle special case URI that requires manual definition\n",
    "    if current_uri == \"http://www.ebi.ac.uk/swo/SWO_0000243\":\n",
    "        uri_to_external_definitions[current_uri] = [\"Jaccard's index\"]\n",
    "    else:\n",
    "        try:\n",
    "            # Attempt to retrieve definition from external source\n",
    "            uri_to_external_definitions[current_uri] = find_definition(current_uri)\n",
    "        except Exception as error:\n",
    "            print(f\"Error retrieving definition for {current_uri}: {error}\")\n",
    "            uri_to_external_definitions[current_uri] = []\n",
    "    \n",
    "    # Save progress every 20 iterations to prevent data loss\n",
    "    if row_index % 20 == 0:\n",
    "        with open(EXTERNAL_DEFINITIONS_FILE, 'w', encoding='utf-8') as output_file:\n",
    "            json.dump(uri_to_external_definitions, output_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"External definitions retrieved for {len(uri_to_external_definitions)} URIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e35e2f8",
   "metadata": {},
   "source": [
    "## Step 4: Merge Definitions from All Sources  \n",
    "\n",
    "Combine definitions from both collection-based and external sources. This step:\n",
    "- Uses sets to automatically eliminate duplicates\n",
    "- Normalizes text by converting to lowercase and stripping whitespace\n",
    "- Provides statistics on coverage and empty definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b1d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URIs in merged definitions: 1760\n",
      "Number of URIs with empty definitions in merged definitions: 0\n"
     ]
    }
   ],
   "source": [
    "# Load definitions from both sources\n",
    "COLLECTION_DEFINITIONS_FILE = \"uri_collection_definitions.json\"\n",
    "EXTERNAL_DEFINITIONS_FILE = \"uri_retrieved_definitions.json\"\n",
    "\n",
    "print(\"Loading definitions from both sources...\")\n",
    "\n",
    "with open(COLLECTION_DEFINITIONS_FILE, 'r', encoding='utf-8') as input_file:\n",
    "    collection_based_definitions = json.load(input_file)\n",
    "\n",
    "with open(EXTERNAL_DEFINITIONS_FILE, 'r', encoding='utf-8') as input_file:\n",
    "    external_definitions = json.load(input_file)\n",
    "\n",
    "# Initialize merged definitions with sets to automatically handle duplicates\n",
    "merged_uri_definitions = {uri: set() for uri in external_definitions.keys()}\n",
    "\n",
    "print(\"Merging definitions from collection sources...\")\n",
    "# Add definitions from collection sources\n",
    "for uri, details in collection_based_definitions.items():\n",
    "    definition_list = details['names']\n",
    "    if len(definition_list) > 0:\n",
    "        # Normalize definitions: lowercase and strip whitespace\n",
    "        normalized_definitions = [definition.lower().strip() for definition in definition_list]\n",
    "        merged_uri_definitions[uri].update(normalized_definitions)\n",
    "\n",
    "print(\"Merging definitions from external sources...\")\n",
    "# Add definitions from external sources  \n",
    "for uri, definition_list in external_definitions.items():\n",
    "    if len(definition_list) > 0:\n",
    "        # Normalize definitions: lowercase and strip whitespace\n",
    "        normalized_definitions = [definition.lower().strip() for definition in definition_list]\n",
    "        merged_uri_definitions[uri].update(normalized_definitions)\n",
    "\n",
    "# Calculate and display statistics\n",
    "total_uris = len(merged_uri_definitions)\n",
    "empty_definitions_count = sum(1 for definitions in merged_uri_definitions.values() if len(definitions) == 0)\n",
    "\n",
    "print(f\"\\n=== Merging Statistics ===\")\n",
    "print(f\"Total URIs processed: {total_uris}\")\n",
    "print(f\"URIs with definitions: {total_uris - empty_definitions_count}\")\n",
    "print(f\"URIs with empty definitions: {empty_definitions_count}\")\n",
    "print(f\"Coverage: {((total_uris - empty_definitions_count) / total_uris * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324b786",
   "metadata": {},
   "source": [
    "## Step 5: Save Merged Definitions\n",
    "\n",
    "Save the merged definitions to a JSON file, converting sets back to lists for JSON serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged definitions to JSON file\n",
    "MERGED_DEFINITIONS_FILE = 'merged_uri_definitions.json'\n",
    "\n",
    "print(f\"Saving merged definitions to {MERGED_DEFINITIONS_FILE}...\")\n",
    "\n",
    "# Convert sets to lists for JSON serialization\n",
    "merged_definitions_for_json = {\n",
    "    uri: list(definition_set) \n",
    "    for uri, definition_set in merged_uri_definitions.items()\n",
    "}\n",
    "\n",
    "with open(MERGED_DEFINITIONS_FILE, 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(merged_definitions_for_json, output_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Successfully saved {len(merged_definitions_for_json)} URI definitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cacc0a0",
   "metadata": {},
   "source": [
    "## Step 6: Generate Indexed Definition Format\n",
    "\n",
    "Create alternative output formats for downstream processing:\n",
    "- **Split definitions**: Each individual definition gets a unique numeric ID\n",
    "- **ID-to-URI mapping**: Maps definition IDs back to their source URIs\n",
    "\n",
    "This format is useful for embedding generation and similarity search systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39fb82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged definitions for processing\n",
    "MERGED_DEFINITIONS_FILE = 'merged_uri_definitions.json'\n",
    "\n",
    "print(f\"Loading merged definitions from {MERGED_DEFINITIONS_FILE}...\")\n",
    "\n",
    "with open(MERGED_DEFINITIONS_FILE, 'r', encoding='utf-8') as input_file:\n",
    "    final_uri_definitions = json.load(input_file)\n",
    "\n",
    "print(f\"Loaded definitions for {len(final_uri_definitions)} URIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b890665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indexed format: assign unique IDs to individual definitions\n",
    "indexed_definitions = {}  # definition_id -> definition_text\n",
    "definition_id_to_uri = {}  # definition_id -> source_uri\n",
    "\n",
    "current_definition_id = 0\n",
    "\n",
    "print(\"Creating indexed definition format...\")\n",
    "\n",
    "# Process each URI and its definitions\n",
    "for source_uri, definition_list in final_uri_definitions.items():\n",
    "    for individual_definition in definition_list:\n",
    "        # Assign unique ID to this definition\n",
    "        indexed_definitions[current_definition_id] = individual_definition\n",
    "        definition_id_to_uri[current_definition_id] = source_uri\n",
    "        current_definition_id += 1\n",
    "\n",
    "# Save the indexed format files\n",
    "SPLIT_DEFINITIONS_FILE = \"split_uri_definitions.json\"\n",
    "ID_TO_URI_FILE = \"id_to_uri.json\"\n",
    "\n",
    "print(f\"Saving {len(indexed_definitions)} individual definitions...\")\n",
    "\n",
    "with open(SPLIT_DEFINITIONS_FILE, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(indexed_definitions, output_file, indent=4)\n",
    "\n",
    "with open(ID_TO_URI_FILE, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(definition_id_to_uri, output_file, indent=4)\n",
    "\n",
    "print(f\"\\n=== Final Output Summary ===\")\n",
    "print(f\"Generated files:\")\n",
    "print(f\"  - {MERGED_DEFINITIONS_FILE}: {len(final_uri_definitions)} URIs with definitions\")\n",
    "print(f\"  - {SPLIT_DEFINITIONS_FILE}: {len(indexed_definitions)} individual definitions\")\n",
    "print(f\"  - {ID_TO_URI_FILE}: {len(definition_id_to_uri)} ID-to-URI mappings\")\n",
    "print(f\"\\nProcessing complete! ðŸŽ‰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GBIErepro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
